{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27251f8d-82c6-4c08-a976-45a029a2f768",
   "metadata": {},
   "source": [
    "# Binary Tabular Data Classification with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a9ac06-674c-4b35-a53e-263080061bec",
   "metadata": {},
   "source": [
    "This notebook covers a classification problem in Machine Learning and go through a comprehensive guide to succesfully develop an End-to-End ML class prediction model using PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e54ffbc-fb99-4ebc-a20f-70e2b35b6064",
   "metadata": {},
   "source": [
    "Classification Algorithms In order to predict the class of certain samples, there are several classification algorithms that can be used. In fact, when developing our machine learning models, we will train and evaluate a certain number of them, and we will keep those with better predicting performance.\n",
    "\n",
    "A non-exhaustive list of some of the most used algorithms are:\n",
    "\n",
    "1) Logistic Regression\n",
    "2) Decision Trees\n",
    "3) Random Forests\n",
    "4) Support Vector Machines\n",
    "5) K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabef528-f4c3-4973-83e1-b109caf0c09c",
   "metadata": {},
   "source": [
    "<b>ROC</b> the metric that we will use in our project is the Reciever Operation Characteristic or ROC. The ROC curve tells us about how good the model can distinguish between two classes. It can get values from 0 to 1. The better the model is, the closer to 1 value it will be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc925470-a375-49cd-8ef1-9222f99ad94c",
   "metadata": {},
   "source": [
    "We will use a number of different supervised algorithms to precisely predict individualsâ€™ income using data collected from the 1994 U.S. Census. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3dc2de-46dc-4196-815b-2fbbda1b2a77",
   "metadata": {},
   "source": [
    "We will then choose the best candidate algorithm from preliminary results and further optimize this algorithm to best model the data. Our goal with this implementation is to build a model that accurately predicts whether an individual makes more than $50,000.\n",
    "\n",
    "<p>Therefore, we are facing a binary classification problem, where we want to determine wether an individual makes more than $50K a year (class 1) or do not (class 0).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "412741ff-bc29-47ed-b191-cc87f3440396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2465c819-4eda-46d9-8bc4-961352c5e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "\n",
    "import pyspark #only run this after findspark.init()\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f82003-6866-4082-b525-5299824c24d9",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bae0108-edc5-4081-a770-b580726f82ac",
   "metadata": {},
   "source": [
    "\r\n",
    "The census dataset consists of approximately 45222 data points, with each datapoint having 13 features\n",
    "The dataset for this project can be found from the UCI Machine Learning Repo.\n",
    "[DATASET](https://archive.ics.uci.edu/dataset/2/adult)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c018a9a-b307-4e3e-b5a3-1c8b88a67417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliaze Spark Session\n",
    "spark = SparkSession.builder.appName('imbalanced_binary_classification').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb68c8f-7eeb-4b15-a37c-9dbfa6f3f860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ABJ-8MM5XZ2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>imbalanced_binary_classification</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1b88c27df60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34611f6f-ec46-420e-8692-29b840c453fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, workClass: string, fnlwgt: int, education: string, education-num: int, marital-status: string, occupation: string, relationship: string, race: string, sex: string, capital-gain: int, capital-loss: int, hours-per-week: int, native-country: string, income: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#File Location and type\n",
    "file_location = \"./adult.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV Options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# make sure to add column name as csv does not contain column name as default\n",
    "\n",
    "df = spark.read.format(file_type) \\\n",
    "   .option(\"inferSchema\", infer_schema)\\\n",
    "   .option(\"header\", first_row_is_header)\\\n",
    "   .option(\"sep\", delimiter)\\\n",
    "   .load(file_location) \\\n",
    "   .toDF(\"age\", \"workClass\", \"fnlwgt\", \"education\", \"education-num\",\"marital-status\", \"occupation\", \"relationship\",\n",
    "        \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e31aa1c-9718-4d83-ae6d-d63bc5ba5c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+------+------------+-------------+--------------+-----------------+--------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "|age|       workClass|fnlwgt|   education|education-num|marital-status|       occupation|  relationship| race|   sex|capital-gain|capital-loss|hours-per-week|native-country|income|\n",
      "+---+----------------+------+------------+-------------+--------------+-----------------+--------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "| 90|               ?| 77053|     HS-grad|            9|       Widowed|                ?| Not-in-family|White|Female|           0|        4356|            40| United-States| <=50K|\n",
      "| 82|         Private|132870|     HS-grad|            9|       Widowed|  Exec-managerial| Not-in-family|White|Female|           0|        4356|            18| United-States| <=50K|\n",
      "| 66|               ?|186061|Some-college|           10|       Widowed|                ?|     Unmarried|Black|Female|           0|        4356|            40| United-States| <=50K|\n",
      "| 54|         Private|140359|     7th-8th|            4|      Divorced|Machine-op-inspct|     Unmarried|White|Female|           0|        3900|            40| United-States| <=50K|\n",
      "| 41|         Private|264663|Some-college|           10|     Separated|   Prof-specialty|     Own-child|White|Female|           0|        3900|            40| United-States| <=50K|\n",
      "| 34|         Private|216864|     HS-grad|            9|      Divorced|    Other-service|     Unmarried|White|Female|           0|        3770|            45| United-States| <=50K|\n",
      "| 38|         Private|150601|        10th|            6|     Separated|     Adm-clerical|     Unmarried|White|  Male|           0|        3770|            40| United-States| <=50K|\n",
      "| 74|       State-gov| 88638|   Doctorate|           16| Never-married|   Prof-specialty|Other-relative|White|Female|           0|        3683|            20| United-States|  >50K|\n",
      "| 68|     Federal-gov|422013|     HS-grad|            9|      Divorced|   Prof-specialty| Not-in-family|White|Female|           0|        3683|            40| United-States| <=50K|\n",
      "| 41|         Private| 70037|Some-college|           10| Never-married|     Craft-repair|     Unmarried|White|  Male|           0|        3004|            60|             ?|  >50K|\n",
      "| 45|         Private|172274|   Doctorate|           16|      Divorced|   Prof-specialty|     Unmarried|Black|Female|           0|        3004|            35| United-States|  >50K|\n",
      "| 38|Self-emp-not-inc|164526| Prof-school|           15| Never-married|   Prof-specialty| Not-in-family|White|  Male|           0|        2824|            45| United-States|  >50K|\n",
      "| 52|         Private|129177|   Bachelors|           13|       Widowed|    Other-service| Not-in-family|White|Female|           0|        2824|            20| United-States|  >50K|\n",
      "| 32|         Private|136204|     Masters|           14|     Separated|  Exec-managerial| Not-in-family|White|  Male|           0|        2824|            55| United-States|  >50K|\n",
      "| 51|               ?|172175|   Doctorate|           16| Never-married|                ?| Not-in-family|White|  Male|           0|        2824|            40| United-States|  >50K|\n",
      "| 46|         Private| 45363| Prof-school|           15|      Divorced|   Prof-specialty| Not-in-family|White|  Male|           0|        2824|            40| United-States|  >50K|\n",
      "| 45|         Private|172822|        11th|            7|      Divorced| Transport-moving| Not-in-family|White|  Male|           0|        2824|            76| United-States|  >50K|\n",
      "| 57|         Private|317847|     Masters|           14|      Divorced|  Exec-managerial| Not-in-family|White|  Male|           0|        2824|            50| United-States|  >50K|\n",
      "| 22|         Private|119592|  Assoc-acdm|           12| Never-married|Handlers-cleaners| Not-in-family|Black|  Male|           0|        2824|            40|             ?|  >50K|\n",
      "| 34|         Private|203034|   Bachelors|           13|     Separated|            Sales| Not-in-family|White|  Male|           0|        2824|            50| United-States|  >50K|\n",
      "+---+----------------+------+------------+-------------+--------------+-----------------+--------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, workClass: string, fnlwgt: int, education: string, education-num: int, marital-status: string, occupation: string, relationship: string, race: string, sex: string, capital-gain: int, capital-loss: int, hours-per-week: int, native-country: string, income: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.show()\n",
    "df.columns\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47a2cf3-604a-460e-84da-a6a6068291cd",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26fc5d3c-e47c-4d70-ae35-2cd70d2f30ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workClass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'education-num',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country',\n",
       " '>50k']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pyspark functions\n",
    "from pyspark.sql import functions as F\n",
    "#create add new column to the dataset\n",
    "df = df.withColumn('>50k', F.when(df.income == '<=50k', 0).otherwise(1))\n",
    "# Drop the income label\n",
    "df = df.drop('income')\n",
    "df.columns\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ea1a191-2d89-448f-8a39-9fa90fe20fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, workClass: string, fnlwgt: int, education: string, education-num: int, marital-status: string, occupation: string, relationship: string, race: string, sex: string, capital-gain: int, capital-loss: int, hours-per-week: int, native-country: string, >50k: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01d453-39c0-45db-be16-cf92cfc02113",
   "metadata": {},
   "source": [
    "#### Vectorizing Numerical Features and One-Hot Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cdb679-582f-4318-b5de-f320ad9eed89",
   "metadata": {},
   "source": [
    "<p>1. Vectorizing Numerical Features:</p>\r",
    "<p>\n",
    "Vectorization is the process of converting numerical features into a numerical vector format. This is often done to standardize or scale numerical features, making them comparable and avoiding issues related to varying scales\n",
    "\r\n",
    "</p>\n",
    "\n",
    "<p>2. One-Hot Encoding Categorical Features:</p>\r",
    "<p>\n",
    "One-hot encoding is a technique used to represent categorical variables as binary vectors. It creates binary columns for each category and indicates the presence of the category with a 1 or 0. This is crucial for machine learning models that require numerical input. Libraries such as scikit-learn provide tools for one-hot encoding:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aa3c65f-1e01-4a62-b5b6-c4984d8c41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting categorical features\n",
    "categorical_columns = [\n",
    " 'workClass',\n",
    " 'education',\n",
    " 'marital-status',\n",
    " 'occupation',\n",
    " 'relationship',\n",
    " 'race',\n",
    " 'sex',\n",
    " 'hours-per-week',\n",
    " 'native-country',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91755d56-b174-43b0-a420-404aec9d0dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import (DecisionTreeClassifier, GBTClassifier, RandomForestClassifier, LogisticRegression)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "# The index of string values multiple column\n",
    "indexers = [\n",
    "    StringIndexer(inputCol = c, outputCol = \"{0}_indexed\".format(c))\n",
    "    for c in categorical_columns]\n",
    "# The encode of indexed values multiple column\n",
    "encoders = [OneHotEncoder(dropLast = False, inputCol= indexer.getOutputCol(),\n",
    "                          outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n",
    "            for indexer in indexers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a3e2d-3c7c-4c2c-8520-95601bd612d5",
   "metadata": {},
   "source": [
    "<p>The above code basically indexes each categorical column using the StringIndexer, and then converts the indexed categories into one-hot encoded variables. The resulting output has the binary vectors appended to the end of each row.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9474f2-6af2-497a-b107-e58cffbca008",
   "metadata": {},
   "source": [
    "#### Join the categorical encoded features with the numerical ones and make a vector with both of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27239829-b4cc-4208-a74d-9b1ab8e93788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing encoded values\n",
    "categorical_encoded = [encoder.getOutputCol() for encoder in encoders]\n",
    "numerical_columns = ['age', 'education-num', 'capital-gain', 'capital-loss']\n",
    "inputcols = categorical_encoded + numerical_columns\n",
    "assembler = VectorAssembler(inputCols= inputcols, outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061bdb8b-a09d-4043-92ab-ec12058e6d0c",
   "metadata": {},
   "source": [
    "#### Set up the pipeline to automatize this stages\n",
    "<p>Pipeline is used to assemble multiple stages (StringIndexers and OneHotEncoders) into a single pipeline.\n",
    "\n",
    "fit is called on the pipeline with the original DataFrame (df), and then transform is applied to execute the transformations.</p>s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "657581a3-cade-4e07-b148-bfbe5477fa3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, workClass: string, fnlwgt: int, education: string, education-num: int, marital-status: string, occupation: string, relationship: string, race: string, sex: string, capital-gain: int, capital-loss: int, hours-per-week: int, native-country: string, >50k: int, workClass_indexed: double, education_indexed: double, marital-status_indexed: double, occupation_indexed: double, relationship_indexed: double, race_indexed: double, sex_indexed: double, hours-per-week_indexed: double, native-country_indexed: double, workClass_indexed_encoded: vector, education_indexed_encoded: vector, marital-status_indexed_encoded: vector, occupation_indexed_encoded: vector, relationship_indexed_encoded: vector, race_indexed_encoded: vector, sex_indexed_encoded: vector, hours-per-week_indexed_encoded: vector, native-country_indexed_encoded: vector, features: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assemble the stages into a Pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders+[assembler])\n",
    "model = pipeline.fit(df)\n",
    "#Transform data\n",
    "transformed = model.transform(df)\n",
    "display(transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8445a825-ea6a-4f73-9cd6-b89247726492",
   "metadata": {},
   "source": [
    "#### Finally, we will select a dataset only with the relevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c659b37-d39c-4d8a-a7ad-d0f396f6b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data\n",
    "final_data = transformed.select('features', '>50k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89aa9b3-1b6e-483a-8972-99ad0a638b22",
   "metadata": {},
   "source": [
    "### 3. Build a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca1fccd2-c10f-4986-91c5-7d445abf1f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classification models\n",
    "# Decision Trees\n",
    "# Random Forests\n",
    "# Gradient Boosted Trees\n",
    "\n",
    "dtc = DecisionTreeClassifier(labelCol = '>50k', featuresCol = 'features')\n",
    "rfc = RandomForestClassifier(numTrees=150, labelCol='>50k', featuresCol = 'features')\n",
    "gbt = GBTClassifier(labelCol= '>50k', featuresCol = 'features', maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c74b3cd9-7c73-4fea-9d9a-c629b7072d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26140\n",
      "6421\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "# We will perform a classic 80/20 split between training and testing data.\n",
    "train_data, test_data = final_data.randomSplit([0.8,0.2], seed=623)\n",
    "print(train_data.count())\n",
    "print(test_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea5a42-977d-4ec8-95e6-a6b1eb7e74bd",
   "metadata": {},
   "source": [
    "### 4. Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7f52f45-dc6c-4b8d-85e4-10f20d7d97ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "gbt_model = gbt.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c00ad7a-8cd8-452d-bab8-e766d7ed6f38",
   "metadata": {},
   "source": [
    "## 5. Evaluate with Test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aab9a7bb-29c5-4ef9-ad05-e52c58743735",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_preds = dtc_model.transform(test_data)\n",
    "rfc_preds = rfc_model.transform(test_data)\n",
    "gbt_preds = gbt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58692993-b84d-4a27-a0c4-a21ef9b7c92b",
   "metadata": {},
   "source": [
    "## 6. Evaluating Model's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e1a84a4-1706-487d-b827-d265a97f6133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our evaluator will be the ROC\n",
    "my_eval = BinaryClassificationEvaluator(labelCol='>50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df2306f2-9ea9-4ec3-add0-89a2d83049f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Display Decision Tree evaluation metric\n",
    "print('DTC')\n",
    "print(my_eval.evaluate(dtc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b34c8a8e-5a88-48c1-83c6-7952bc02d3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Display Random Forest evaluation metric\n",
    "print('RFC')\n",
    "print(my_eval.evaluate(rfc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5256864-2c40-4754-9287-9fc0754b1c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Display Gradien Boosting Tree evaluation metric\n",
    "print('GBT')\n",
    "print(my_eval.evaluate(gbt_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3b59d-9183-4161-ac5f-1738cf1e5b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improving Model Performance (Model Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd34127f-546b-4d9d-bb6a-f99aa0388f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
