{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94db2423-993a-4437-9d4b-faf566331746",
   "metadata": {},
   "source": [
    "# PySpark Dataframe Complete Guide (with COVID-19 Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6d4626-bb60-4b00-ac38-65b660d79d52",
   "metadata": {},
   "source": [
    "While once upon a time Spark used to be heavily reliant on RDD manipulations, Spark has now provided a DataFrame API for us to work with. you can get dataset from [Here] : https://www.kaggle.com/datasets/sudalairajkumar/covid19-in-india"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3329181-bd83-43ff-bb46-ed6a5b699b2c",
   "metadata": {},
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c75b5155-83b5-495e-aca8-9affcd9a658a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: findspark\n",
      "Version: 2.0.1\n",
      "Summary: Find pyspark to make it importable.\n",
      "Home-page: https://github.com/minrk/findspark\n",
      "Author: Min RK\n",
      "Author-email: benjaminrk@gmail.com\n",
      "License: BSD (3-clause)\n",
      "Location: c:\\users\\anerisonani\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b218251c-2162-4d7b-ad2a-e8321da88461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "\n",
    "import pyspark # only run this after findspark.init()\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.types import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "560016e8-7fca-44ea-b70c-f0557f1e7fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('covid-example').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb922d59-f2e7-4e2c-8a22-6b82c78dafa0",
   "metadata": {},
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f985d10-83f2-4d65-bc42-e1118ddb85f8",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbbd578-d5ad-4ba7-a569-7e341c8eceaf",
   "metadata": {},
   "source": [
    "We will be working with the Data Science for COVID-19 in India, which is one of the most detailed datasets on the internet for COVID.\r\n",
    "\r\n",
    "Data can be found in this kaggle URL Li : nk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79af658-34ec-4654-98bd-cd87306365d5",
   "metadata": {},
   "source": [
    "## 1. Basics Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e418d64-b3fa-4e7a-9ceb-3f78849ac12c",
   "metadata": {},
   "source": [
    "### 1) Load the data\n",
    "#### And Create a dataframe named cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1d1f9b8-180e-401e-b2df-7c09c7ea76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = spark.read.load(\"covid_19_india.csv\",\n",
    "                        format=\"csv\", \n",
    "                        sep=\",\", \n",
    "                        inferSchema=\"true\", \n",
    "                        header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8debec5-2f4e-45f1-84e7-7865ac89467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b860f84-0764-4e91-b8c6-604a6c45131c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------+--------------------+-----------------------+------------------------+-----+------+---------+\n",
      "|Sno|               Date|   Time|State/UnionTerritory|ConfirmedIndianNational|ConfirmedForeignNational|Cured|Deaths|Confirmed|\n",
      "+---+-------------------+-------+--------------------+-----------------------+------------------------+-----+------+---------+\n",
      "|  1|2020-01-30 00:00:00|6:00 PM|              Kerala|                      1|                       0|    0|     0|        1|\n",
      "|  2|2020-01-31 00:00:00|6:00 PM|              Kerala|                      1|                       0|    0|     0|        1|\n",
      "|  3|2020-02-01 00:00:00|6:00 PM|              Kerala|                      2|                       0|    0|     0|        2|\n",
      "|  4|2020-02-02 00:00:00|6:00 PM|              Kerala|                      3|                       0|    0|     0|        3|\n",
      "|  5|2020-02-03 00:00:00|6:00 PM|              Kerala|                      3|                       0|    0|     0|        3|\n",
      "|  6|2020-02-04 00:00:00|6:00 PM|              Kerala|                      3|                       0|    0|     0|        3|\n",
      "|  7|2020-02-05 00:00:00|6:00 PM|              Kerala|                      3|                       0|    0|     0|        3|\n",
      "|  8|2020-02-06 00:00:00|6:00 PM|              Kerala|                      3|                       0|    0|     0|        3|\n",
      "|  9|2020-02-07 00:00:00|6:00 PM|              Kerala|                      3|                       0|    0|     0|        3|\n",
      "| 10|2020-02-08 00:00:00|6:00 PM|              Kerala|                      3|                       0|    0|     0|        3|\n",
      "+---+-------------------+-------+--------------------+-----------------------+------------------------+-----+------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cases.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8276121d-dcca-4657-8393-19db81316915",
   "metadata": {},
   "source": [
    "#### 2) Create a global Temporary view for SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4243e6a4-4268-4be0-b0e1-0a0277362a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.createTempView(\"covid_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38a3eec6-fbfa-4478-9616-afacce8061d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.sql(\"SELECT * FROM covid_df where `State/UnionTerritory` = 'Gujarat' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c0d3bf6-43ea-4b04-967c-c3572f3c2949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+--------+--------------------+-----------------------+------------------------+-----+------+---------+\n",
      "|Sno|               Date|    Time|State/UnionTerritory|ConfirmedIndianNational|ConfirmedForeignNational|Cured|Deaths|Confirmed|\n",
      "+---+-------------------+--------+--------------------+-----------------------+------------------------+-----+------+---------+\n",
      "|232|2020-03-20 00:00:00| 6:00 PM|             Gujarat|                      5|                       0|    0|     0|        5|\n",
      "|252|2020-03-21 00:00:00| 6:00 PM|             Gujarat|                      7|                       0|    0|     0|        7|\n",
      "|275|2020-03-22 00:00:00| 6:00 PM|             Gujarat|                     18|                       0|    0|     1|       18|\n",
      "|298|2020-03-23 00:00:00| 6:00 PM|             Gujarat|                     29|                       0|    0|     1|       29|\n",
      "|321|2020-03-24 00:00:00| 6:00 PM|             Gujarat|                     32|                       1|    0|     1|       33|\n",
      "|345|2020-03-25 00:00:00| 6:00 PM|             Gujarat|                     37|                       1|    0|     1|       38|\n",
      "|373|2020-03-26 00:00:00| 6:00 PM|             Gujarat|                     42|                       1|    0|     3|       43|\n",
      "|400|2020-03-27 00:00:00|10:00 AM|             Gujarat|                     42|                       1|    0|     3|       43|\n",
      "|427|2020-03-28 00:00:00| 6:00 PM|             Gujarat|                     44|                       1|    0|     3|       45|\n",
      "|454|2020-03-29 00:00:00| 7:30 PM|             Gujarat|                      -|                       -|    1|     5|       58|\n",
      "|481|2020-03-30 00:00:00| 9:30 PM|             Gujarat|                      -|                       -|    1|     6|       69|\n",
      "|509|2020-03-31 00:00:00| 8:30 PM|             Gujarat|                      -|                       -|    3|     6|       73|\n",
      "|538|2020-04-01 00:00:00| 7:30 PM|             Gujarat|                      -|                       -|    5|     6|       82|\n",
      "|567|2020-04-02 00:00:00| 6:00 PM|             Gujarat|                      -|                       -|    8|     7|       87|\n",
      "|597|2020-04-03 00:00:00| 6:00 PM|             Gujarat|                      -|                       -|   10|     8|       95|\n",
      "|628|2020-04-04 00:00:00| 6:00 PM|             Gujarat|                      -|                       -|   14|    10|      105|\n",
      "|658|2020-04-05 00:00:00| 6:00 PM|             Gujarat|                      -|                       -|   18|    11|      122|\n",
      "|688|2020-04-06 00:00:00| 6:00 PM|             Gujarat|                      -|                       -|   22|    12|      144|\n",
      "|718|2020-04-07 00:00:00| 6:00 PM|             Gujarat|                      -|                       -|   25|    13|      165|\n",
      "|749|2020-04-08 00:00:00| 5:00 PM|             Gujarat|                      -|                       -|   25|    13|      165|\n",
      "+---+-------------------+--------+--------------------+-----------------------+------------------------+-----+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a00dd72c-527b-4408-bb8f-18dde7606b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas==1.5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cceb0a-1b68-458c-96dd-bc3a19c022bd",
   "metadata": {},
   "source": [
    " It looks ok right now, but sometimes as we the number of columns increases, the formatting becomes not too great. The.toPandas() function converts a Spark Dataframe into a Pandas Dataframe, which is much easier to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a23fb8f8-6ee4-4aae-ae13-c472010fb902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\spark-3.3.2\\python\\pyspark\\sql\\pandas\\conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>State/UnionTerritory</th>\n",
       "      <th>ConfirmedIndianNational</th>\n",
       "      <th>ConfirmedForeignNational</th>\n",
       "      <th>Cured</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>6:00 PM</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>6:00 PM</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>6:00 PM</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>298</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>6:00 PM</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>6:00 PM</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>345</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>6:00 PM</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>373</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>6:00 PM</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>400</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>10:00 AM</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>427</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>6:00 PM</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>454</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>7:30 PM</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sno       Date      Time State/UnionTerritory ConfirmedIndianNational  \\\n",
       "0  232 2020-03-20   6:00 PM              Gujarat                       5   \n",
       "1  252 2020-03-21   6:00 PM              Gujarat                       7   \n",
       "2  275 2020-03-22   6:00 PM              Gujarat                      18   \n",
       "3  298 2020-03-23   6:00 PM              Gujarat                      29   \n",
       "4  321 2020-03-24   6:00 PM              Gujarat                      32   \n",
       "5  345 2020-03-25   6:00 PM              Gujarat                      37   \n",
       "6  373 2020-03-26   6:00 PM              Gujarat                      42   \n",
       "7  400 2020-03-27  10:00 AM              Gujarat                      42   \n",
       "8  427 2020-03-28   6:00 PM              Gujarat                      44   \n",
       "9  454 2020-03-29   7:30 PM              Gujarat                       -   \n",
       "\n",
       "  ConfirmedForeignNational  Cured  Deaths  Confirmed  \n",
       "0                        0      0       0          5  \n",
       "1                        0      0       0          7  \n",
       "2                        0      0       1         18  \n",
       "3                        0      0       1         29  \n",
       "4                        1      0       1         33  \n",
       "5                        1      0       1         38  \n",
       "6                        1      0       3         43  \n",
       "7                        1      0       3         43  \n",
       "8                        1      0       3         45  \n",
       "9                        -      1       5         58  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdd6ca06-cc1e-49c1-81ef-3ce924edc23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sno: integer (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- State/UnionTerritory: string (nullable = true)\n",
      " |-- ConfirmedIndianNational: string (nullable = true)\n",
      " |-- ConfirmedForeignNational: string (nullable = true)\n",
      " |-- Cured: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cases.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c027a74-61e6-41be-b8ba-b4af59dee5dc",
   "metadata": {},
   "source": [
    "#### 3) To change a single column,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d53eabe8-8f12-43d4-b3d6-397dde74aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = cases.withColumnRenamed(\"State/UnionTerritory\", \"state\")\n",
    "df2 = df2.withColumnRenamed(\"ConfirmedIndianNational\", \"ConfirmedCases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2302a29-dc5f-4a2f-9a19-c1b4e62732c5",
   "metadata": {},
   "source": [
    "#### We can select a subset of columns using the select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00e7b99b-7e62-4500-a18d-350249a82bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+-----+------+---------+\n",
      "|               Date|ConfirmedCases|Cured|Deaths|Confirmed|\n",
      "+-------------------+--------------+-----+------+---------+\n",
      "|2020-03-20 00:00:00|             5|    0|     0|        5|\n",
      "|2020-03-21 00:00:00|             7|    0|     0|        7|\n",
      "|2020-03-22 00:00:00|            18|    0|     1|       18|\n",
      "|2020-03-23 00:00:00|            29|    0|     1|       29|\n",
      "|2020-03-24 00:00:00|            32|    0|     1|       33|\n",
      "|2020-03-25 00:00:00|            37|    0|     1|       38|\n",
      "|2020-03-26 00:00:00|            42|    0|     3|       43|\n",
      "|2020-03-27 00:00:00|            42|    0|     3|       43|\n",
      "|2020-03-28 00:00:00|            44|    0|     3|       45|\n",
      "|2020-03-29 00:00:00|             -|    1|     5|       58|\n",
      "|2020-03-30 00:00:00|             -|    1|     6|       69|\n",
      "|2020-03-31 00:00:00|             -|    3|     6|       73|\n",
      "|2020-04-01 00:00:00|             -|    5|     6|       82|\n",
      "|2020-04-02 00:00:00|             -|    8|     7|       87|\n",
      "|2020-04-03 00:00:00|             -|   10|     8|       95|\n",
      "|2020-04-04 00:00:00|             -|   14|    10|      105|\n",
      "|2020-04-05 00:00:00|             -|   18|    11|      122|\n",
      "|2020-04-06 00:00:00|             -|   22|    12|      144|\n",
      "|2020-04-07 00:00:00|             -|   25|    13|      165|\n",
      "|2020-04-08 00:00:00|             -|   25|    13|      165|\n",
      "+-------------------+--------------+-----+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df2.select('Date','ConfirmedCases','Cured','Deaths', 'Confirmed')\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966cafdc-23d4-4800-90e5-1e3b44fe9bf5",
   "metadata": {},
   "source": [
    "#### 4) Sort by Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "186c1ec4-3187-49e0-81d2-2f2e96f219f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+-----+------+---------+\n",
      "|               Date|ConfirmedCases|Cured|Deaths|Confirmed|\n",
      "+-------------------+--------------+-----+------+---------+\n",
      "|2020-03-20 00:00:00|             5|    0|     0|        5|\n",
      "|2020-03-21 00:00:00|             7|    0|     0|        7|\n",
      "|2020-03-22 00:00:00|            18|    0|     1|       18|\n",
      "|2020-03-23 00:00:00|            29|    0|     1|       29|\n",
      "|2020-03-24 00:00:00|            32|    0|     1|       33|\n",
      "|2020-03-25 00:00:00|            37|    0|     1|       38|\n",
      "|2020-03-26 00:00:00|            42|    0|     3|       43|\n",
      "|2020-03-27 00:00:00|            42|    0|     3|       43|\n",
      "|2020-03-28 00:00:00|            44|    0|     3|       45|\n",
      "|2020-03-29 00:00:00|             -|    1|     5|       58|\n",
      "|2020-03-30 00:00:00|             -|    1|     6|       69|\n",
      "|2020-03-31 00:00:00|             -|    3|     6|       73|\n",
      "|2020-04-01 00:00:00|             -|    5|     6|       82|\n",
      "|2020-04-02 00:00:00|             -|    8|     7|       87|\n",
      "|2020-04-03 00:00:00|             -|   10|     8|       95|\n",
      "|2020-04-04 00:00:00|             -|   14|    10|      105|\n",
      "|2020-04-05 00:00:00|             -|   18|    11|      122|\n",
      "|2020-04-06 00:00:00|             -|   22|    12|      144|\n",
      "|2020-04-07 00:00:00|             -|   25|    13|      165|\n",
      "|2020-04-08 00:00:00|             -|   25|    13|      165|\n",
      "+-------------------+--------------+-----+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple sort\n",
    "df2.sort(\"Confirmed\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c55cb65-9de1-43c5-8d99-7ec23585f114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+------+------+---------+\n",
      "|               Date|ConfirmedCases| Cured|Deaths|Confirmed|\n",
      "+-------------------+--------------+------+------+---------+\n",
      "|2021-08-11 00:00:00|             -|814802| 10077|   825085|\n",
      "|2021-08-10 00:00:00|             -|814778| 10077|   825064|\n",
      "|2021-08-09 00:00:00|             -|814761| 10077|   825045|\n",
      "|2021-08-08 00:00:00|             -|814747| 10077|   825020|\n",
      "|2021-08-07 00:00:00|             -|814720| 10077|   825001|\n",
      "|2021-08-06 00:00:00|             -|814696| 10076|   824978|\n",
      "|2021-08-05 00:00:00|             -|814665| 10076|   824954|\n",
      "|2021-08-04 00:00:00|             -|814637| 10076|   824939|\n",
      "|2021-08-03 00:00:00|             -|814595| 10076|   824922|\n",
      "|2021-08-02 00:00:00|             -|814570| 10076|   824900|\n",
      "|2021-08-01 00:00:00|             -|814549| 10076|   824877|\n",
      "|2021-07-31 00:00:00|             -|814514| 10076|   824850|\n",
      "|2021-07-30 00:00:00|             -|814485| 10076|   824829|\n",
      "|2021-07-29 00:00:00|             -|814452| 10076|   824802|\n",
      "|2021-07-28 00:00:00|             -|814413| 10076|   824774|\n",
      "|2021-07-27 00:00:00|             -|814356| 10076|   824744|\n",
      "|2021-07-26 00:00:00|             -|814307| 10076|   824713|\n",
      "|2021-07-25 00:00:00|             -|814265| 10076|   824683|\n",
      "|2021-07-24 00:00:00|             -|814223| 10076|   824644|\n",
      "|2021-07-23 00:00:00|             -|814162| 10076|   824608|\n",
      "+-------------------+--------------+------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Descending Sort\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df2.sort(F.desc(\"Confirmed\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8fa21-9cad-418b-8928-4f9a65923307",
   "metadata": {},
   "source": [
    "#### 5) Change Column Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d72d5fb8-7d50-4bc2-8175-b03565940e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+-----+------+---------+\n",
      "|               Date|ConfirmedCases|Cured|Deaths|Confirmed|\n",
      "+-------------------+--------------+-----+------+---------+\n",
      "|2020-03-20 00:00:00|             5|    0|     0|        5|\n",
      "|2020-03-21 00:00:00|             7|    0|     0|        7|\n",
      "|2020-03-22 00:00:00|            18|    0|     1|       18|\n",
      "|2020-03-23 00:00:00|            29|    0|     1|       29|\n",
      "|2020-03-24 00:00:00|            32|    0|     1|       33|\n",
      "|2020-03-25 00:00:00|            37|    0|     1|       38|\n",
      "|2020-03-26 00:00:00|            42|    0|     3|       43|\n",
      "|2020-03-27 00:00:00|            42|    0|     3|       43|\n",
      "|2020-03-28 00:00:00|            44|    0|     3|       45|\n",
      "|2020-03-29 00:00:00|             -|    1|     5|       58|\n",
      "|2020-03-30 00:00:00|             -|    1|     6|       69|\n",
      "|2020-03-31 00:00:00|             -|    3|     6|       73|\n",
      "|2020-04-01 00:00:00|             -|    5|     6|       82|\n",
      "|2020-04-02 00:00:00|             -|    8|     7|       87|\n",
      "|2020-04-03 00:00:00|             -|   10|     8|       95|\n",
      "|2020-04-04 00:00:00|             -|   14|    10|      105|\n",
      "|2020-04-05 00:00:00|             -|   18|    11|      122|\n",
      "|2020-04-06 00:00:00|             -|   22|    12|      144|\n",
      "|2020-04-07 00:00:00|             -|   25|    13|      165|\n",
      "|2020-04-08 00:00:00|             -|   25|    13|      165|\n",
      "+-------------------+--------------+-----+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "df2 = df2.withColumn('Date', F.col('Date').cast(TimestampType()))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4383339f-08b5-4540-a424-e852acec878e",
   "metadata": {},
   "source": [
    "#### 6) Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d8614-c7b0-4d56-b7e0-caa0c29a181e",
   "metadata": {},
   "source": [
    "We can filter a data frame using multiple conditions using AND(&), OR(|) and NOT(~) conditions. For example, we may want to find out all the different infection_case in Sikkim with more than 10 confirmed cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d640958-d479-429e-a26d-a53a6cb9cdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-------+------+-----------------------+------------------------+-----+------+---------+\n",
      "| Sno|               Date|   Time| state|ConfirmedIndianNational|ConfirmedForeignNational|Cured|Deaths|Confirmed|\n",
      "+----+-------------------+-------+------+-----------------------+------------------------+-----+------+---------+\n",
      "|2875|2020-06-10 00:00:00|8:00 AM|Sikkim|                      -|                       -|    0|     0|       13|\n",
      "|2912|2020-06-11 00:00:00|8:00 AM|Sikkim|                      -|                       -|    0|     0|       13|\n",
      "|2948|2020-06-12 00:00:00|8:00 AM|Sikkim|                      -|                       -|    2|     0|       14|\n",
      "|2984|2020-06-13 00:00:00|8:00 AM|Sikkim|                      -|                       -|    2|     0|       63|\n",
      "|3020|2020-06-14 00:00:00|8:00 AM|Sikkim|                      -|                       -|    4|     0|       63|\n",
      "|3056|2020-06-15 00:00:00|8:00 AM|Sikkim|                      -|                       -|    4|     0|       68|\n",
      "|3092|2020-06-16 00:00:00|8:00 AM|Sikkim|                      -|                       -|    4|     0|       68|\n",
      "|3128|2020-06-17 00:00:00|8:00 AM|Sikkim|                      -|                       -|    4|     0|       70|\n",
      "|3164|2020-06-18 00:00:00|8:00 AM|Sikkim|                      -|                       -|    4|     0|       70|\n",
      "|3200|2020-06-19 00:00:00|8:00 AM|Sikkim|                      -|                       -|    5|     0|       70|\n",
      "|3236|2020-06-20 00:00:00|8:00 AM|Sikkim|                      -|                       -|    5|     0|       70|\n",
      "|3272|2020-06-21 00:00:00|8:00 AM|Sikkim|                      -|                       -|   25|     0|       70|\n",
      "|3308|2020-06-22 00:00:00|8:00 AM|Sikkim|                      -|                       -|   25|     0|       78|\n",
      "|3344|2020-06-23 00:00:00|8:00 AM|Sikkim|                      -|                       -|   29|     0|       78|\n",
      "|3380|2020-06-24 00:00:00|8:00 AM|Sikkim|                      -|                       -|   29|     0|       79|\n",
      "|3416|2020-06-25 00:00:00|8:00 AM|Sikkim|                      -|                       -|   39|     0|       84|\n",
      "|3452|2020-06-26 00:00:00|8:00 AM|Sikkim|                      -|                       -|   39|     0|       85|\n",
      "|3488|2020-06-27 00:00:00|8:00 AM|Sikkim|                      -|                       -|   39|     0|       86|\n",
      "|3524|2020-06-28 00:00:00|8:00 AM|Sikkim|                      -|                       -|   46|     0|       87|\n",
      "|3560|2020-06-29 00:00:00|8:00 AM|Sikkim|                      -|                       -|   49|     0|       88|\n",
      "+----+-------------------+-------+------+-----------------------+------------------------+-----+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cases.filter((cases.Confirmed>10) & (cases.state=='Sikkim')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b84ec44-9fdf-4303-b3ee-eaefdd1b54d8",
   "metadata": {},
   "source": [
    "#### 7) GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1a3f3eb-b89d-4389-9eb3-7b7572685865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------+\n",
      "|               State|Confirmed|sum(Confirmed)|\n",
      "+--------------------+---------+--------------+\n",
      "|           Jharkhand|       27|            27|\n",
      "|             Haryana|      225|           225|\n",
      "|      Andhra Pradesh|      722|           722|\n",
      "|          Chandigarh|       30|            60|\n",
      "|           Jharkhand|       67|            67|\n",
      "|           Karnataka|      705|           705|\n",
      "|         West Bengal|     2063|          2063|\n",
      "|              Punjab|     1980|          1980|\n",
      "|         Uttarakhand|      317|           317|\n",
      "|             Tripura|      800|           800|\n",
      "|             Manipur|      490|           490|\n",
      "|                 Goa|     1482|          2964|\n",
      "|           Karnataka|    44077|         44077|\n",
      "|           Jharkhand|    11686|         11686|\n",
      "|           Rajasthan|    58692|         58692|\n",
      "|        Chhattisgarh|    14987|         14987|\n",
      "|           Telengana|    92255|         92255|\n",
      "|              Sikkim|     1232|          1232|\n",
      "|             Manipur|     4925|          4925|\n",
      "|   Jammu and Kashmir|    32647|         32647|\n",
      "|          Tamil Nadu|   379385|        379385|\n",
      "|          Puducherry|    12434|         12434|\n",
      "|             Mizoram|     1003|          1003|\n",
      "|Dadra and Nagar H...|     2671|          2671|\n",
      "|               Bihar|   158285|        158285|\n",
      "|         Uttarakhand|    31973|         31973|\n",
      "|         Maharashtra|  1167496|       1167496|\n",
      "|       Uttar Pradesh|   342788|        342788|\n",
      "|          Tamil Nadu|   547337|        547337|\n",
      "|               Bihar|   171255|        171255|\n",
      "|Dadra and Nagar H...|     2977|          2977|\n",
      "|         Maharashtra|  1351153|       1351153|\n",
      "|               Assam|   191397|        191397|\n",
      "|   Arunachal Pradesh|    11998|         11998|\n",
      "|           Karnataka|   802817|        802817|\n",
      "+--------------------+---------+--------------+\n",
      "only showing top 35 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group = cases.groupBy([\"State\", \"Confirmed\"]).agg(F.sum(\"Confirmed\"))\n",
    "group.show(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e874d70f-94b0-4b48-9ce8-a94be1c01981",
   "metadata": {},
   "source": [
    "#### 8)  Use SQL with DataFrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1617816-fa0f-4203-9bb1-9e18486d4ddc",
   "metadata": {},
   "source": [
    "We first register the cases dataframe to a temporary table cases_table on which we can run SQL operations. As you can see, the result of the SQL select statement is again a Spark Dataframe.\r\n",
    "\r\n",
    "All complex SQL queries like GROUP BY, HAVING, AND ORDER BY clauses can be applied in 'Sql' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3ffd55-3970-4d47-9bfb-bf437fde06cf",
   "metadata": {},
   "source": [
    "# cases_for_sql = sqlCtx.read.csv(\"covid_19_india.csv\")\n",
    "cases.registerTempTable('cases_table')\n",
    "newDF = spark.sql('select * from cases_table where confirmed > 100')\n",
    "newDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091ae811-9b76-45d1-9ecb-0bde84d4a4ef",
   "metadata": {},
   "source": [
    "#### 9) Using Spark UDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88933cfb-0f3d-4c5c-b9bf-486f0cfa6c21",
   "metadata": {},
   "source": [
    "Sometimes we want to do complicated things to a column or multiple columns. This could be thought of as a map operation on a PySpark Dataframe to a single column or multiple columns. While Spark SQL functions do solve many use cases when it comes to column creation, I use Spark UDF whenever I need more matured Python functionality. \\\r\n",
    "\r\n",
    "To use Spark UDFs, we need to use the F.udf function to convert a regular python function to a Spark UDF. We also need to specify the return type of the function. In this example the return type is StringType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbb0bc3c-f66a-4407-bd83-1c1de5056e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------+------+-----------------------+------------------------+-----+------+---------+-------+\n",
      "|Sno|               Date|   Time| state|ConfirmedIndianNational|ConfirmedForeignNational|Cured|Deaths|Confirmed|HighLow|\n",
      "+---+-------------------+-------+------+-----------------------+------------------------+-----+------+---------+-------+\n",
      "|  1|2020-01-30 00:00:00|6:00 PM|Kerala|                      1|                       0|    0|     0|        1|    low|\n",
      "|  2|2020-01-31 00:00:00|6:00 PM|Kerala|                      1|                       0|    0|     0|        1|    low|\n",
      "|  3|2020-02-01 00:00:00|6:00 PM|Kerala|                      2|                       0|    0|     0|        2|    low|\n",
      "|  4|2020-02-02 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "|  5|2020-02-03 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "|  6|2020-02-04 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "|  7|2020-02-05 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "|  8|2020-02-06 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "|  9|2020-02-07 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "| 10|2020-02-08 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "| 11|2020-02-09 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "| 12|2020-02-10 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "| 13|2020-02-11 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "| 14|2020-02-12 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "| 15|2020-02-13 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "| 16|2020-02-14 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "| 17|2020-02-15 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "| 18|2020-02-16 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "| 19|2020-02-17 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "| 20|2020-02-18 00:00:00|6:00 PM|Kerala|                      3|                       0|    0|     0|        3|    low|\n",
      "+---+-------------------+-------+------+-----------------------+------------------------+-----+------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def caesesHighLow(confirmed):\n",
    "    if confirmed < 50:\n",
    "        return 'low'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "# convert to a UDF Function by passing in the function and return type of function\n",
    "\n",
    "casesHighLowUDF = F.udf(caesesHighLow, StringType())\n",
    "CasesWithHighLow = cases.withColumn(\"HighLow\", casesHighLowUDF(\"Confirmed\"))\n",
    "CasesWithHighLow.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6330ca3-7b6a-46a0-b9ca-5538da6d826e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
